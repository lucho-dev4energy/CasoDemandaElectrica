# INFORME DE TRABAJO FINAL DEL PROYECTO
# CURSO: INTELIGENCIA ARTIFICIAL APLICADA AL SECTOR ELÉCTRICO
# ALUMNO: LUIS ALBERTO VIDAL GUEVARA
# TEMA: PRONÓSTICO DE DEMANDA ELÉCTRICA REGIÓN PJM EAST

## 1. INTRODUCCIÓN Y CONTEXTO
La predicción precisa de la demanda eléctrica es un componente crítico para la operación eficiente y segura de los sistemas de potencia. En el contexto del sector eléctrico moderno, caracterizado por la integración de energías renovables y la necesidad de eficiencia económica, los operadores del sistema (ISO/RTO) requieren herramientas avanzadas para estimar el consumo futuro.

Este proyecto aborda el problema de pronóstico de carga a corto y mediano plazo utilizando técnicas de Inteligencia Artificial y Machine Learning. Se trabaja con datos reales de la interconexión PJM (Región Este), aplicando una metodología rigurosa que va desde la exploración de datos hasta la implementación de modelos de ensamble avanzados.

## 2. OBJETIVOS
### 2.1. Objetivo General
Desarrollar y evaluar modelos de Machine Learning capaces de pronosticar el consumo eléctrico horario (MW) con alta precisión, minimizando el error porcentual medio.

### 2.2. Objetivos Específicos
*   Realizar un Análisis Exploratorio de Datos (EDA) para comprender los patrones estacionales y tendencias del consumo.
*   Implementar técnicas de Ingeniería de Características (Feature Engineering) para enriquecer el dataset con variables temporales y de retardo (lags).
*   Desarrollar tres modelos predictivos de complejidad incremental: Regresión Lineal, Random Forest y Gradient Boosting.
*   Comparar el desempeño de los modelos utilizando métricas estándar de la industria (MAE, RMSE, MAPE, R²).

## 3. DESCRIPCIÓN DE LOS DATOS Y PREPROCESAMIENTO
**Fuente de Datos:** Histórico de consumo horario de PJM Interconnection (Región Este).
**Variable Objetivo:** `PJME_MW` (Demanda en Megavatios).
**Horizonte Temporal:** Datos históricos desde 2002 hasta 2018.

**Proceso de Limpieza:**
1.  **Conversión de Fechas:** Se transformó la columna de fecha/hora al formato `datetime` de Pandas y se estableció como índice del DataFrame.
2.  **Manejo de Outliers:** Se identificaron valores atípicos, como consumos inusualmente bajos (< 15,000 MW), que podrían corresponder a fallas de medición o cortes de servicio, para evitar que sesguen el entrenamiento.

## 4. ANÁLISIS EXPLORATORIO DE DATOS (EDA)
El análisis visual y estadístico reveló patrones fundamentales del comportamiento eléctrico:
*   **Ciclo Diario:** Se observó la típica curva de "doble joroba" en invierno y pico único vespertino en verano, reflejando hábitos residenciales y comerciales.
*   **Ciclo Semanal:** Diferencias marcadas entre días laborables y fines de semana, siendo estos últimos de menor consumo.
*   **Estacionalidad Anual:** Picos claros en verano (aire acondicionado) e invierno (calefacción), con valles en primavera y otoño (temporadas de transición).

## 5. INGENIERÍA DE CARACTERÍSTICAS (FEATURE ENGINEERING)
Para que los modelos de Machine Learning (que no son nativos de series temporales) puedan aprender patrones temporales, se crearon variables explicativas artificiales:

1.  **Variables de Calendario:**
    *   `hour`, `dayofweek`, `quarter`, `month`, `year`, `dayofyear`.
    *   Estas variables permiten al modelo aprender efectos como "los lunes a las 8am sube el consumo".

2.  **Variables de Retardo (Lags):**
    *   `lag_1`: Consumo de la hora anterior. Captura la inercia térmica y operativa inmediata.
    *   `lag_24`: Consumo de la misma hora del día anterior. Captura la periodicidad diaria.
    *   Se eliminaron las filas con valores `NaN` generados por el desplazamiento de datos.

## 6. METODOLOGÍA DE MODELADO
**Estrategia de División de Datos (Split):**
Se utilizó una división cronológica estricta para respetar la naturaleza temporal de los datos y evitar el "Data Leakage" (fuga de información del futuro al pasado).
*   **Conjunto de Entrenamiento (Train):** Datos previos al 01-01-2017.
*   **Conjunto de Prueba (Test):** Datos desde el 01-01-2017 en adelante.

**Métricas de Evaluación:**
*   **MAE (Mean Absolute Error):** Error promedio en MW. Fácil de interpretar.
*   **RMSE (Root Mean Squared Error):** Penaliza errores grandes.
*   **MAPE (Mean Absolute Percentage Error):** Error relativo porcentual. Métricas clave para la industria.
*   **R² (Coeficiente de Determinación):** Capacidad del modelo para explicar la varianza de los datos.

## 7. DESARROLLO DE MODELOS Y RESULTADOS

### 7.1. Modelo 1: Regresión Lineal (Baseline)
*   **Descripción:** Modelo simple que asume una relación lineal entre las variables de tiempo/lags y la demanda.
*   **Resultados:**
    *   MAE: 976.56 MW
    *   MAPE: 3.15%
    *   R²: 0.9583
*   **Análisis:** Buen punto de partida, pero incapaz de capturar las no-linealidades complejas del comportamiento humano y climático.

### 7.2. Modelo 2: Random Forest Regressor
*   **Descripción:** Modelo de ensamble basado en Bagging (Bootstrap Aggregating). Crea múltiples árboles de decisión en paralelo y promedia sus resultados. Robusto ante ruido y outliers.
*   **Configuración:** `n_estimators=100`, `max_depth=20`.
*   **Resultados:**
    *   MAE: 597.59 MW
    *   MAPE: 1.92%
    *   R²: 0.9832
*   **Análisis:** Mejora significativa respecto a la regresión lineal. Excelente manejo de relaciones no lineales.

### 7.3. Modelo 3: Gradient Boosting Regressor (Campeador)
*   **Descripción:** Modelo de ensamble basado en Boosting. Construye árboles de forma secuencial, donde cada árbol intenta corregir los errores del anterior.
*   **Configuración:** `n_estimators=1000`, `learning_rate=0.01`.
*   **Resultados:**
    *   MAE: **326.06 MW**
    *   MAPE: **1.03%**
    *   R²: **0.9949**
*   **Análisis:** Rendimiento superior. Logra un error casi despreciable (1%) para propósitos operativos.

## 8. COMPARACIÓN FINAL Y DISCUSIÓN
La siguiente tabla resume el desempeño en el conjunto de prueba (datos desconocidos para el modelo):

| Modelo | MAE (MW) | RMSE (MW) | R² | MAPE (%) |
| :--- | :--- | :--- | :--- | :--- |
| **Gradient Boosting** | **326.06** | **438.08** | **0.9949** | **1.03%** |
| Random Forest | 597.59 | 794.76 | 0.9832 | 1.92% |
| Regresión Lineal | 976.56 | 1,250.44 | 0.9583 | 3.15% |

### 8.1. Análisis Comparativo de Desempeño
El modelo de Gradient Boosting superó consistentemente a las otras arquitecturas en todas las métricas evaluadas. Su capacidad para reducir el MAE a 326.06 MW representa una mejora del 45% respecto al Random Forest y del 66% respecto a la Regresión Lineal. Esto valida la hipótesis de que los métodos de boosting, al corregir iterativamente los errores de predicción, son superiores para capturar la estructura fina de la demanda eléctrica.

### 8.2. Interpretación de la Importancia de Variables (Feature Importance)
El análisis de importancia de características en los modelos basados en árboles reveló una jerarquía clara en los predictores:
1.  **Dominancia de la Inercia (`lag_1`):** La variable más influyente fue el consumo de la hora anterior. Esto indica que el sistema eléctrico tiene una "memoria" de corto plazo muy fuerte; el estado actual depende fundamentalmente del estado inmediato anterior.
2.  **Ciclicidad Diaria (`lag_24`):** El segundo predictor más potente fue el consumo a la misma hora del día anterior, capturando los hábitos de consumo repetitivos de la población y la industria.
3.  **Variables de Calendario:** Aunque menos críticas que los lags, las variables como `hour` y `dayofweek` fueron esenciales para modelar los perfiles de carga intra-diarios y las diferencias entre días laborales y festivos.

## 9. CONCLUSIONES
1.  **Viabilidad Tecnológica:** El uso de algoritmos de Boosting (como XGBoost o GradientBoostingRegressor de scikit-learn) es altamente efectivo para series temporales de alta frecuencia como la demanda eléctrica. Su capacidad para reducir el sesgo y la varianza de forma secuencial los hace superiores a modelos más simples o incluso a otros métodos de ensamble como Random Forest en contextos donde la precisión es crítica.
2.  **Importancia de la Ingeniería de Características:** La incorporación de variables de retardo (lags) demostró ser el factor más determinante para el rendimiento predictivo, superando en impacto a la propia selección del algoritmo. Esto confirma que, en problemas de series temporales de energía, la correcta representación de la inercia del sistema y los patrones cíclicos (diarios y semanales) es fundamental.
3.  **Impacto Operativo y Económico:** Lograr un modelo con un error porcentual (MAPE) cercano al 1% tiene implicaciones directas en la operación del sistema eléctrico. Permite a los operadores reducir los márgenes de reserva rodante y optimizar el despacho económico, traduciéndose en una operación más eficiente y en una reducción significativa de costos operativos y de penalizaciones por desvíos.
4.  **Limitaciones de los Modelos Lineales:** El bajo desempeño relativo de la Regresión Lineal (MAPE > 3%) evidenció que la relación entre la demanda eléctrica y sus factores determinantes es intrínsecamente no lineal. Los modelos lineales no logran capturar adecuadamente la saturación de la demanda en picos extremos ni las interacciones complejas entre variables temporales.
5.  **Generalización y Robustez:** El modelo de Gradient Boosting demostró una excelente capacidad de generalización al ser evaluado en un conjunto de prueba temporalmente separado (2017 en adelante). Esto sugiere que el modelo no ha "memorizado" los datos de entrenamiento, sino que ha aprendido patrones estructurales robustos que se mantienen en el tiempo, validando su uso en entornos de producción reales.

## 10. RECOMENDACIONES FUTURAS
1.  **Integración de Variables Meteorológicas:** Se recomienda encarecidamente incorporar datos históricos de temperatura, humedad y radiación solar. La demanda eléctrica es altamente sensible al clima (efecto térmico), y la inclusión de estas variables exógenas es el siguiente paso lógico para reducir los errores residuales, especialmente durante olas de calor o frío extremo.
2.  **Exploración de Modelos de Aprendizaje Profundo (Deep Learning):** Evaluar arquitecturas de redes neuronales recurrentes, específicamente LSTM (Long Short-Term Memory) o GRU (Gated Recurrent Units). Estas redes están diseñadas específicamente para capturar dependencias temporales de largo plazo y no linealidades complejas que podrían escapar a los modelos de árboles de decisión tradicionales.
3.  **Implementación de MLOps y Reentrenamiento Continuo:** Desarrollar un pipeline automatizado de MLOps que permita el monitoreo constante del desempeño del modelo (detección de *Data Drift*) y su reentrenamiento periódico. El comportamiento del consumo eléctrico evoluciona con el tiempo, y un sistema estático perderá precisión si no se actualiza con nuevos datos.
4.  **Optimización Avanzada de Hiperparámetros:** Realizar una búsqueda exhaustiva de hiperparámetros utilizando técnicas como Bayesian Optimization o RandomizedSearchCV. Aunque el modelo actual tiene un buen desempeño, un ajuste fino de parámetros como la tasa de aprendizaje, la profundidad de los árboles y el número de estimadores podría exprimir aún más la precisión del modelo.
5.  **Análisis Desagregado de Errores:** Llevar a cabo un diagnóstico detallado de los errores del modelo estratificado por hora del día, día de la semana y temporada. Identificar los momentos específicos donde el modelo falla (por ejemplo, días festivos atípicos o transiciones de horario de verano) permitiría desarrollar estrategias de corrección específicas, como modelos dedicados para días especiales.

---
**Bibliografía y Herramientas Utilizadas:**
*   Python 3.14
*   Librerías: Pandas, NumPy, Scikit-Learn, Matplotlib, Seaborn.
*   Entorno: Google Colab / Google Antigravity.
